{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948cfec9-65fc-4063-85b3-e646f26588ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f4b35c-65dd-4cab-bcfc-b7f29e4e3d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor u c say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah dont think goes usf lives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>nd time tried contact u u won pound prize clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>pity mood soany suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>guy did bitching acted like id interested buyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>rofl true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                            message\n",
       "0         0  jurong point crazy available bugis n great wor...\n",
       "1         0                            ok lar joking wif u oni\n",
       "2         1  free entry wkly comp win fa cup final tkts st ...\n",
       "3         0                        u dun say early hor u c say\n",
       "4         0                      nah dont think goes usf lives\n",
       "...     ...                                                ...\n",
       "5567      1  nd time tried contact u u won pound prize clai...\n",
       "5568      0                          b going esplanade fr home\n",
       "5569      0                        pity mood soany suggestions\n",
       "5570      0  guy did bitching acted like id interested buyi...\n",
       "5571      0                                          rofl true\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "\n",
    "# Convert labels to binary (ham = 0, spam = 1)\n",
    "data['class'] = data['class'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize by splitting and remove stop words\n",
    "    tokens = [word for word in text.split() if word not in ENGLISH_STOP_WORDS]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['message'] = data['message'].apply(preprocess_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082316fe-dd04-4583-a6fa-49666a7d7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['message']\n",
    "y = data['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6563f644-1978-41e0-a9a3-d60eca40810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_words = 5000  # Max vocabulary size\n",
    "max_len = 100     # Max length for padding\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences and pad them\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35520eeb-426d-4420-b7da-09d5560039c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6846d1bc-b8c0-4694-abfa-fd3f265b2071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - accuracy: 0.8464 - loss: 0.4695 - val_accuracy: 0.8621 - val_loss: 0.4017\n",
      "Epoch 2/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.8754 - loss: 0.4070 - val_accuracy: 0.8621 - val_loss: 0.4017\n",
      "Epoch 3/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.8605 - loss: 0.4245 - val_accuracy: 0.8621 - val_loss: 0.4045\n",
      "Epoch 4/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.8754 - loss: 0.3961 - val_accuracy: 0.8621 - val_loss: 0.4014\n",
      "Epoch 5/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.8643 - loss: 0.4116 - val_accuracy: 0.8621 - val_loss: 0.4012\n",
      "Epoch 6/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.8702 - loss: 0.4024 - val_accuracy: 0.8621 - val_loss: 0.4013\n",
      "Epoch 7/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.8586 - loss: 0.4176 - val_accuracy: 0.8621 - val_loss: 0.4011\n",
      "Epoch 8/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.8703 - loss: 0.3987 - val_accuracy: 0.8621 - val_loss: 0.4044\n",
      "Epoch 9/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.8702 - loss: 0.4021 - val_accuracy: 0.8621 - val_loss: 0.4013\n",
      "Epoch 10/10\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.8667 - loss: 0.4072 - val_accuracy: 0.8621 - val_loss: 0.4012\n"
     ]
    }
   ],
   "source": [
    "# Early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, validation_split=0.2, epochs=10, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddd2f0ef-d4c0-4584-acc4-710b7c836565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Accuracy: 0.8654708520179372\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor u c say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah dont think goes usf lives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                            message\n",
       "0      0  jurong point crazy available bugis n great wor...\n",
       "1      0                            ok lar joking wif u oni\n",
       "2      1  free entry wkly comp win fa cup final tkts st ...\n",
       "3      0                        u dun say early hor u c say\n",
       "4      0                      nah dont think goes usf lives"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f7c987f-0051-4297-900a-79fe72276bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(model, tokenizer, message):\n",
    "    # Preprocess the input message (same steps as training data)\n",
    "    message = message.lower()\n",
    "    message = re.sub(r'[^a-zA-Z\\s]', '', message)\n",
    "    tokens = [word for word in message.split() if word not in ENGLISH_STOP_WORDS]\n",
    "    processed_message = ' '.join(tokens)\n",
    "    \n",
    "    # Tokenize and pad the message\n",
    "    message_seq = tokenizer.texts_to_sequences([processed_message])\n",
    "    message_pad = pad_sequences(message_seq, maxlen=max_len, padding='post')\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    prediction = model.predict(message_pad)\n",
    "    return \"spam\" if prediction > 0.5 else \"ham\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32a56d41-2564-43b6-813f-57ec0308da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Message: Congratulations! You've won a $1000 Walmart gift card. Click here to claim.\n",
      "Classified as: ham\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Message: Are we still on for lunch tomorrow?\n",
      "Classified as: ham\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Message: Urgent: Your account is compromised. Please update your password immediately.\n",
      "Classified as: ham\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example messages\n",
    "new_messages = [\"Congratulations! You've won a $1000 Walmart gift card. Click here to claim.\",\n",
    "    \"Are we still on for lunch tomorrow?\",\n",
    "    \"Urgent: Your account is compromised. Please update your password immediately.\"]\n",
    "\n",
    "# Classify each message\n",
    "for msg in new_messages:\n",
    "    result = classify_message(model, tokenizer, msg)\n",
    "    print(f\"Message: {msg}\\nClassified as: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ed738e5-e715-477e-966b-b86a18cb3274",
   "metadata": {},
   "source": [
    "#### Strengths of Using RNNs for Text Classification\n",
    "\n",
    "1.Sequence Sensitivity : RNNs are specifically designed to handle sequential data, which makes them effective at understanding context in text sequences. This is beneficial in distinguishing between spam and ham, especially in cases where specific word orders are important.\n",
    "2.Memory of Previous Words : Unlike traditional models like Naive Bayes or Support Vector Machines, RNNs maintain a sense of the previous context in the message, which can be crucial in accurately identifying the nature of the text (e.g., spam messages often have specific structural patterns).\n",
    "3.Flexibility with Sequence Lengths : RNNs can theoretically handle varying sequence lengths, which is useful for email messages of different lengths."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2e9c417-65ea-44a4-bf32-32aa02a836eb",
   "metadata": {},
   "source": [
    "#### Weaknesses and Limitations of RNNs\n",
    "1.Vanishing Gradient Problem: RNNs may struggle with long sequences due to the vanishing gradient problem, making it harder to learn dependencies in longer text. This could limit their effectiveness for lengthy messages where key information might appear toward the end.\n",
    "2.Training Time: RNNs, especially LSTMs, can be computationally expensive and time-consuming to train compared to simpler models like Naive Bayes, which may be better suited for large-scale datasets.\n",
    "3.Sensitivity to Word Order in Short Texts: In some cases, spam messages might not have an exact sequence pattern but rely on certain keywords. RNNs could overemphasize word order, which may be less relevant for spam detection.\n",
    "Difficulty Handling Rare or New Words: RNNs might misclassify messages containing uncommon words or phrases that were rare in the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
